
# ğŸ§  Tá»”NG QUAN Dá»° ÃN

## ğŸ¯ Má»¥c tiÃªu

`LLM Provider Balancing (LPB)` lÃ  **má»™t service trung gian** tÆ°Æ¡ng thÃ­ch vá»›i **OpenAI API**, cho phÃ©p:

* Gá»­i request Ä‘áº¿n nhiá»u LLM provider (OpenAI, Gemini, Claude, v.v.)
* Tá»± Ä‘á»™ng **cÃ¢n báº±ng táº£i theo token, táº§n suáº¥t, hiá»‡u suáº¥t, chi phÃ­, lá»—i 403**
* Quáº£n lÃ½ cáº¥u hÃ¬nh linh hoáº¡t qua file **YAML hoáº·c REST API**
* Cung cáº¥p **log, metrics, storage backend** cÃ³ thá»ƒ má»Ÿ rá»™ng

---

# ğŸ§© KIáº¾N TRÃšC Há»† THá»NG

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Client (SDK, app) â”‚
â”‚  - openai-python      â”‚
â”‚  - openai-go, etc.    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      LLM Provider Balancer   â”‚
â”‚   (API tÆ°Æ¡ng thÃ­ch OpenAI)   â”‚
â”‚                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚ API Layer (OpenAI API) â”‚ â”‚
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚   â”‚ Balancer Engine        â”‚ â”‚
â”‚   â”‚  - Token selector      â”‚ â”‚
â”‚   â”‚  - Error recovery      â”‚ â”‚
â”‚   â”‚  - Weight policy       â”‚ â”‚
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚   â”‚ Provider Adapters      â”‚ â”‚
â”‚   â”‚  - openai.go           â”‚ â”‚
â”‚   â”‚  - gemini.go           â”‚ â”‚
â”‚   â”‚  - claude.go           â”‚ â”‚
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚   â”‚ Storage & Log Plugins  â”‚ â”‚
â”‚   â”‚  - redis / file / yaml â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ External LLM Providers                 â”‚
â”‚  - OpenAI, Gemini, Anthropic, v.v.     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ§± Cáº¤U TRÃšC Dá»° ÃN (Go)

```
llm-balancer/
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ truckllm/
â”‚       â””â”€â”€ main.go
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ api/              # OpenAI-compatible endpoints
â”‚   â”‚   â”œâ”€â”€ chat_completions.go
â”‚   â”‚   â”œâ”€â”€ completions.go
â”‚   â”‚   â”œâ”€â”€ embeddings.go
â”‚   â”‚   â””â”€â”€ models.go
â”‚   â”œâ”€â”€ balancer/
â”‚   â”‚   â”œâ”€â”€ selector.go   # Strategy logic
â”‚   â”‚   â”œâ”€â”€ metrics.go    # Prometheus counters
â”‚   â”‚   â””â”€â”€ policy.go
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ config.go     # Load YAML â†’ struct
â”‚   â”œâ”€â”€ provider/
â”‚   â”‚   â”œâ”€â”€ interface.go
â”‚   â”‚   â”œâ”€â”€ openai.go
â”‚   â”‚   â”œâ”€â”€ gemini.go
â”‚   â”‚   â”œâ”€â”€ claude.go
â”‚   â”‚   â””â”€â”€ registry.go
â”‚   â”œâ”€â”€ log/
â”‚   â”‚   â””â”€â”€ logger.go
â”‚   â”œâ”€â”€ store/
â”‚   â”‚   â”œâ”€â”€ redis.go
â”‚   â”‚   â”œâ”€â”€ file.go
â”‚   â”‚   â””â”€â”€ interface.go
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ retry.go
â”œâ”€â”€ pkg/
â”‚   â””â”€â”€ middleware/
â”‚       â”œâ”€â”€ auth.go
â”‚       â”œâ”€â”€ request_id.go
â”‚       â””â”€â”€ logging.go
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ webui/                # optional management UI (Vue/React)
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Makefile
â”œâ”€â”€ go.mod
â”œâ”€â”€ go.sum
â””â”€â”€ README.md
```

---

# âš™ï¸ Cáº¤U HÃŒNH YAML (config.yaml)

```yaml
version: "1.0"

server:
  port: 8080
  log_level: info
  enable_metrics: true

balancer:
  strategy: round_robin   # or "least_error", "weighted"
  retry_on_403: true
  max_retry: 2

providers:
  - name: openai
    type: openai
    api_keys:
      - sk-xxx1
      - sk-xxx2
  - name: gemini
    type: gemini
    api_keys:
      - gk-abc1
      - gk-abc2
    base_url: https://generativelanguage.googleapis.com/v1
  - name: claude
    type: anthropic
    api_keys:
      - ak-xxx

models:
  gpt-4o: openai:gpt-4o
  gemini-1.5-pro: gemini:gemini-1.5-pro
  claude-3-opus: claude:claude-3-opus

storage:
  type: redis
  config:
    host: redis:6379
    password: ""
    db: 0

logging:
  type: file
  config:
    path: ./logs/requests.log
```

---

# ğŸ³ DOCKER SETUP

### **Dockerfile**

```dockerfile
FROM golang:1.23-alpine AS builder
WORKDIR /app
COPY . .
RUN go build -o truckllm ./cmd/truckllm

FROM alpine:3.19
WORKDIR /app
COPY --from=builder /app/truckllm .
COPY configs/config.yaml ./configs/config.yaml
CMD ["./truckllm", "-config", "configs/config.yaml"]
```

---

### **docker-compose.yml**

```yaml
version: '3.8'
services:
  truckllm:
    build: .
    ports:
      - "8080:8080"
    environment:
      - CONFIG_PATH=/app/configs/config.yaml
    depends_on:
      - redis
    volumes:
      - ./logs:/app/logs
  redis:
    image: redis:7
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

volumes:
  redis_data:
```

---

# ğŸ“Š OBSERVABILITY

### Prometheus metrics (máº·c Ä‘á»‹nh báº­t á»Ÿ `/metrics`):

| Metric                     | MÃ´ táº£                                     |
| -------------------------- | ----------------------------------------- |
| `llm_requests_total`       | Tá»•ng sá»‘ request tá»«ng provider             |
| `llm_failures_total`       | Sá»‘ request lá»—i                            |
| `llm_avg_latency_seconds`  | Äá»™ trá»… trung bÃ¬nh                         |
| `llm_balance_distribution` | Tá»· lá»‡ request phÃ¢n phá»‘i giá»¯a cÃ¡c provider |

### Log plugin

* Há»— trá»£ cÃ¡c backend:

  * `file` (máº·c Ä‘á»‹nh)
  * `prometheus pushgateway`
  * `stdout`
  * `custom webhook` (ngÆ°á»i dÃ¹ng Ä‘á»‹nh nghÄ©a)

---

# ğŸ§  BALANCING STRATEGY

| Strategy    | MÃ´ táº£                                   | Use case                         |
| ----------- | --------------------------------------- | -------------------------------- |
| Round Robin | LuÃ¢n phiÃªn token                        | BÃ¬nh thÆ°á»ng                      |
| Least Error | Æ¯u tiÃªn token Ã­t lá»—i 403 nháº¥t           | Chá»‘ng rate-limit                 |
| Weighted    | PhÃ¢n bá»• theo trá»ng sá»‘ (hiá»‡u suáº¥t / giÃ¡) | Khi cÃ³ nhiá»u tÃ i khoáº£n khÃ¡c nhau |
| Smart       | Há»c tá»« log, dá»± Ä‘oÃ¡n provider hiá»‡u quáº£   | Giai Ä‘oáº¡n má»Ÿ rá»™ng sau            |

---

# ğŸ§° CI/CD Gá»¢I Ã

* **GitHub Actions**

  * Build + lint Go
  * Run tests (`go test ./...`)
  * Build Docker image â†’ push Docker Hub
* **Makefile**

  ```makefile
  build:
      go build -o bin/truckllm ./cmd/truckllm
  run:
      ./bin/truckllm -config configs/config.yaml
  docker:
      docker build -t truckllm:latest .
  test:
      go test ./...
  ```

---

# ğŸŒ Má» Rá»˜NG TÆ¯Æ NG LAI

* ğŸ”Œ UI quáº£n lÃ½ (webui/)

  * CRUD config YAML (front-end dÃ¹ng Vue 3 + PrimeVue)
  * Realtime log & metrics chart
* ğŸ§© Plugin SDK (Go interface)

  * Cho phÃ©p cá»™ng Ä‘á»“ng viáº¿t thÃªm log/storage provider
* ğŸ§® Token Quota tracking (per-key, per-user)
* ğŸ’° Cost optimization layer (giáº£m chi phÃ­ báº±ng cÃ¡ch chá»n model ráº» khi tÆ°Æ¡ng Ä‘Æ°Æ¡ng)

---

# âœ… Káº¾T LUáº¬N

| ThÃ nh pháº§n        | CÃ´ng nghá»‡                            |
| ----------------- | ------------------------------------ |
| Language          | **Go**                               |
| Config            | **YAML**                             |
| API compatibility | **OpenAI format**                    |
| Storage           | Redis / File                         |
| Logging           | File / Prometheus / Plugin           |
| Observability     | Prometheus                           |
| Packaging         | Docker, Docker Compose               |
| Extension         | UI (Vue), Plugin system              |
| Strategy          | Round Robin / Weighted / Error-Aware |
