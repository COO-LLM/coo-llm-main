# üß† TruckLLM

**M·ªôt reverse proxy th√¥ng minh cho c√°c h·ªá th·ªëng LLM**, t∆∞∆°ng th√≠ch ho√†n to√†n v·ªõi OpenAI API, gi√∫p c√¢n b·∫±ng t·∫£i gi·ªØa nhi·ªÅu t√†i kho·∫£n (API keys) v√† nhi·ªÅu nh√† cung c·∫•p (OpenAI, Gemini, Claude, v.v.), ƒë·ªìng th·ªùi h·ªó tr·ª£ logging, storage linh ho·∫°t v√† c·∫•u h√¨nh YAML nh∆∞ Docker Compose.

---

## ‚öôÔ∏è 1. M·ª•c ti√™u h·ªá th·ªëng

| M·ª•c ti√™u                    | M√¥ t·∫£                                                                                                    |
| --------------------------- | -------------------------------------------------------------------------------------------------------- |
| **API t∆∞∆°ng th√≠ch OpenAI**  | Ng∆∞·ªùi d√πng ch·ªâ c·∫ßn thay `https://api.openai.com/v1` ‚Üí `https://llm-balancer.local/v1` m√† kh√¥ng ƒë·ªïi code. |
| **C√¢n b·∫±ng t·∫£i th√¥ng minh** | Gi·ªØa nhi·ªÅu API key v√† nhi·ªÅu provider ƒë·ªÉ tr√°nh 403 / 429 / overload.                                      |
| **C·∫•u h√¨nh linh ho·∫°t**      | T·∫•t c·∫£ config trong file YAML gi·ªëng Docker Compose / K8s.                                                |
| **Quan s√°t & gi√°m s√°t d·ªÖ**  | T√≠ch h·ª£p Prometheus, file log, ho·∫∑c user-defined log provider.                                           |
| **M·ªü r·ªông d·ªÖ d√†ng**         | Cho ph√©p th√™m provider m·ªõi (local ho·∫∑c public API) m√† kh√¥ng ƒë·ªïi code.                                    |
| **Hi·ªáu nƒÉng cao**           | Vi·∫øt b·∫±ng Go, h·ªó tr·ª£ concurrency & streaming t·ªët.                                                        |

---

## üß© 2. Ki·∫øn tr√∫c t·ªïng th·ªÉ

### üî∑ S∆° ƒë·ªì t·ªïng quan

```
                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ   Client / SDK (OpenAI)   ‚îÇ
                  ‚îÇ  (requests to /v1/* APIs) ‚îÇ
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   LLM Provider Balancer  ‚îÇ
                    ‚îÇ (drop-in OpenAI gateway) ‚îÇ
                    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
                    ‚îÇ  API Layer (/v1 routes)   ‚îÇ
                    ‚îÇ  Balancer Logic           ‚îÇ
                    ‚îÇ  Provider Adapters        ‚îÇ
                    ‚îÇ  Storage (Redis/File)     ‚îÇ
                    ‚îÇ  Logging (File/Prom/Graf) ‚îÇ
                    ‚îÇ  Config Loader (YAML)     ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ                    ‚îÇ                    ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ OpenAI Provider Adapter ‚îÇ‚îÇ Gemini Adapter    ‚îÇ‚îÇ Claude Adapter     ‚îÇ
‚îÇ  (api.openai.com)       ‚îÇ‚îÇ  (googleapis.com) ‚îÇ‚îÇ  (api.anthropic.com)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üì¶ 3. C·∫•u tr√∫c d·ª± √°n (Go)

```
llm-balancer/
‚îú‚îÄ‚îÄ cmd/
‚îÇ   ‚îî‚îÄ‚îÄ main.go
‚îú‚îÄ‚îÄ internal/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat_completions.go
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ completions.go
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embeddings.go
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ models.go
‚îÇ   ‚îú‚îÄ‚îÄ balancer/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ selector.go
‚îÇ   ‚îú‚îÄ‚îÄ provider/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ interface.go
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ openai.go
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gemini.go
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ claude.go
‚îÇ   ‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.go
‚îÇ   ‚îú‚îÄ‚îÄ store/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ runtime_store.go
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config_store.go
‚îÇ   ‚îî‚îÄ‚îÄ log/
‚îÇ       ‚îú‚îÄ‚îÄ logger.go
‚îÇ       ‚îî‚îÄ‚îÄ prometheus.go
‚îú‚îÄ‚îÄ config.example.yaml
‚îú‚îÄ‚îÄ go.mod
‚îî‚îÄ‚îÄ go.sum
```

---

## üß± 4. C·∫•u h√¨nh YAML (v√≠ d·ª•)

```yaml
version: "1.0"

server:
  listen: ":8080"
  admin_api_key: "admin-secret"

logging:
  file:
    enabled: true
    path: "./logs/llm.log"
    max_size_mb: 100
    max_backups: 5
  prometheus:
    enabled: true
    endpoint: "/metrics"
  providers:
    - name: "webhook"
      type: "http"
      endpoint: "https://logs.example.com/ingest"
      batch:
        enabled: true
        size: 50
        interval_seconds: 10

storage:
  config:
    type: "file"
    path: "./config.yaml"
  runtime:
    type: "redis"
    addr: "localhost:6379"
    password: ""

providers:
  - id: "openai"
    name: "OpenAI"
    base_url: "https://api.openai.com/v1"
    keys:
      - id: "oa-1"
        secret: "${OPENAI_KEY_1}"
        limit_req_per_min: 200
        limit_tokens_per_min: 100000
  - id: "gemini"
    name: "Gemini"
    base_url: "https://generativelanguage.googleapis.com/v1"
    keys:
      - id: "gm-1"
        secret: "${GEMINI_KEY_1}"
        limit_req_per_min: 150
        limit_tokens_per_min: 80000
  - id: "claude"
    name: "Claude"
    base_url: "https://api.anthropic.com/v1"
    keys:
      - id: "cl-1"
        secret: "${CLAUDE_KEY_1}"
        limit_req_per_min: 100
        limit_tokens_per_min: 60000

model_aliases:
  gpt-4o: openai:gpt-4o
  gemini-1.5-pro: gemini:gemini-1.5-pro
  claude-3-opus: claude:claude-3-opus

policy:
  strategy: "hybrid" # cost-first | least-used | hybrid
  hybrid_weights:
    token_ratio: 0.5
    req_ratio: 0.3
    error_score: 0.1
    latency: 0.1
```

---

## üîß 5. API Interface (t∆∞∆°ng th√≠ch OpenAI)

| Method | Endpoint               | M√¥ t·∫£                               |
| ------ | ---------------------- | ----------------------------------- |
| `POST` | `/v1/chat/completions` | T·∫°o ph·∫£n h·ªìi h·ªôi tho·∫°i (nh∆∞ OpenAI) |
| `POST` | `/v1/completions`      | Sinh vƒÉn b·∫£n thu·∫ßn                  |
| `POST` | `/v1/embeddings`       | T·∫°o vector embedding                |
| `GET`  | `/v1/models`           | Danh s√°ch models hi·ªán c√≥            |

> T·∫•t c·∫£ d√πng `Authorization: Bearer <api_key>` ‚Äî mapping t·ªõi provider config.

---

## ‚öñÔ∏è 6. Balancer Logic

### M·ª•c ti√™u:

* Ph√¢n ph·ªëi request h·ª£p l√Ω theo:

  * S·ªë request / ph√∫t (`req_usage`)
  * S·ªë token / ph√∫t (`token_usage`)
  * Error rate
  * Latency trung b√¨nh

### Pseudocode:

```go
func SelectBest(model string) (*Provider, string) {
    provider := config.ResolveProvider(model)
    keys := runtime.GetActiveKeys(provider)
    
    best := keys[0]
    score := math.MaxFloat64
    for _, key := range keys {
        s := weightedScore(key)
        if s < score {
            best = key
            score = s
        }
    }
    return provider, best
}
```

---

## üåâ 7. Provider Interface

```go
type Provider interface {
	Name() string
	Generate(ctx context.Context, req Request) (*Response, error)
	ListModels(ctx context.Context) ([]string, error)
}

type Request struct {
	Model string                 `json:"model"`
	Input map[string]interface{} `json:"input"`
}

type Response struct {
	RawResponse []byte
	HTTPCode    int
	Err         error
}
```

---

## üß© 8. API Layer (Chat Completion v√≠ d·ª•)

```go
func ChatCompletionsHandler(w http.ResponseWriter, r *http.Request) {
	var payload map[string]interface{}
	json.NewDecoder(r.Body).Decode(&payload)
	model := payload["model"].(string)

	provider, key := balancer.SelectBest(model)
	resp, err := provider.Generate(r.Context(), balancer.ToProviderRequest(payload))
	if err != nil {
		http.Error(w, err.Error(), 500)
		return
	}

	w.Header().Set("Content-Type", "application/json")
	w.WriteHeader(resp.HTTPCode)
	w.Write(resp.RawResponse)
}
```

---

## üß∞ 9. Storage Layer

### Runtime Store (Redis)

* Gi·ªØ usage count / minute / key
* D·∫°ng:

  ```
  key_usage:{provider}:{key_id}:req
  key_usage:{provider}:{key_id}:tokens
  ```
* TTL: 60s
* D√πng Lua script ƒë·ªÉ update atomic.

### Config Store

* `FileConfigStore`: load YAML t·ª´ file (default)
* `HTTPConfigStore`: load t·ª´ remote API
* `S3ConfigStore`: optional (cho distributed config)

---

## üßæ 10. Logging

### T√πy ch·ªçn logging:

| Lo·∫°i             | M·ª•c ƒë√≠ch                         |
| ---------------- | -------------------------------- |
| File             | Log ho·∫°t ƒë·ªông & l·ªói local        |
| Prometheus       | Metric cho Grafana               |
| Webhook Provider | Log t·ªõi endpoint user ƒë·ªãnh nghƒ©a |

M·ªói entry:

```json
{
  "timestamp": "2025-10-12T12:00:00Z",
  "provider": "gemini",
  "model": "gemini-1.5-pro",
  "req_id": "uuid",
  "latency_ms": 423,
  "status": 200,
  "tokens": 190,
  "error": ""
}
```

---

## üß≠ 11. Admin API (Qu·∫£n tr·ªã c·∫•u h√¨nh)

| Method | Endpoint                    | M√¥ t·∫£                         |
| ------ | --------------------------- | ----------------------------- |
| `GET`  | `/admin/v1/config`          | L·∫•y config hi·ªán t·∫°i           |
| `POST` | `/admin/v1/config/validate` | Ki·ªÉm tra YAML h·ª£p l·ªá          |
| `POST` | `/admin/v1/config`          | C·∫≠p nh·∫≠t config m·ªõi           |
| `POST` | `/admin/v1/reload`          | Hot-reload c·∫•u h√¨nh           |
| `GET`  | `/admin/v1/providers`       | Li·ªát k√™ provider & tr·∫°ng th√°i |
| `GET`  | `/admin/v1/logs`            | Tail log g·∫ßn nh·∫•t             |

B·∫£o m·∫≠t: `Authorization: Bearer <admin_api_key>`

---

## üñ•Ô∏è 12. Web Dashboard (t√πy ch·ªçn)

X√¢y b·∫±ng **Vue 3 + Tailwind** ho·∫∑c **SvelteKit**:

* **Dashboard t·ªïng quan**: TPS, token/min, error rate
* **Providers**: danh s√°ch key, health, quota
* **Config editor**: YAML live validate + apply
* **Log viewer**: realtime tail + filter theo provider

---

## üîí 13. B·∫£o m·∫≠t

* M√£ h√≥a API keys trong config (AES ho·∫∑c KMS)
* Ch·∫∑n request kh√¥ng c√≥ Authorization
* Kh√¥ng ghi secret v√†o log
* Gi·ªõi h·∫°n request/second / IP (rate limiter)
* TLS b·∫Øt bu·ªôc trong production

---

## üßÆ 14. Tri·ªÉn khai

**Dockerfile**

```dockerfile
FROM golang:1.23-alpine AS build
WORKDIR /app
COPY . .
RUN go build -o llm-balancer ./cmd

FROM alpine
COPY --from=build /app/llm-balancer /usr/local/bin/
CMD ["llm-balancer", "-config", "/etc/llm/config.yaml"]
```

**docker-compose.yaml**

```yaml
services:
  llm-balancer:
    image: llm-balancer:latest
    ports:
      - "8080:8080"
    volumes:
      - ./config.yaml:/etc/llm/config.yaml
    environment:
      - REDIS_ADDR=redis:6379
  redis:
    image: redis:7
```

---

## üìä 15. Quan s√°t (Observability)

* `/metrics` ‚Üí Prometheus endpoint
* C√°c metric:

  ```
  llm_requests_total{provider="openai"}
  llm_latency_ms_avg{provider="gemini"}
  llm_error_rate{provider="claude"}
  llm_active_keys_total
  ```
* Grafana dashboard template k√®m s·∫µn.

---

## üîß 16. M·ªü r·ªông

| M·ªü r·ªông              | √ù nghƒ©a                             |
| -------------------- | ----------------------------------- |
| Caching Layer        | Cache response embeddings / prompts |
| Weighted Cost Policy | L·ª±a ch·ªçn model r·∫ª nh·∫•t tr∆∞·ªõc        |
| Token Translator     | Mapping model alias t·ª± ƒë·ªông         |
| Auto Key Disable     | T·ª± disable key khi 403 qu√° nhi·ªÅu    |
| Multi-instance       | Redis cluster + stateless backend   |

---

## üí° 17. Ng√¥n ng·ªØ & Th∆∞ vi·ªán ch√≠nh

| Th√†nh ph·∫ßn   | C√¥ng ngh·ªá                      |
| ------------ | ------------------------------ |
| **Ng√¥n ng·ªØ** | Go 1.23                        |
| **Web**      | `net/http`, `chi` ho·∫∑c `gin`   |
| **Storage**  | `go-redis`, `viper`, `yaml.v3` |
| **Logging**  | `zerolog` ho·∫∑c `zap`           |
| **Metrics**  | `prometheus/client_golang`     |
| **Testing**  | `testify`, `httptest`          |

---

## üß∞ 18. L·ª£i √≠ch ch√≠nh

‚úÖ T∆∞∆°ng th√≠ch ho√†n to√†n v·ªõi SDK OpenAI (Python, JS, v.v.)
‚úÖ C·∫•u h√¨nh YAML d·ªÖ hi·ªÉu, portable
‚úÖ H·ªó tr·ª£ multi-provider, multi-key, balancing
‚úÖ Logging + metrics chu·∫©n production
‚úÖ M·ªü r·ªông d·ªÖ (th√™m provider, th√™m log sink)
‚úÖ Vi·∫øt b·∫±ng Go ‚Üí t·ªëc ƒë·ªô, concurrency, memory t·ªët

---

## üöÄ 19. H∆∞·ªõng ph√°t tri·ªÉn ti·∫øp theo

1. **T√≠ch h·ª£p caching / quota policy**
2. **Vi·∫øt plugin provider (local llama, ollama, etc.)**
3. **Th√™m CLI qu·∫£n l√Ω (`truckllmctl`)**
4. **WebUI admin (SvelteKit)**
5. **Tri·ªÉn khai Helm chart cho K8s**

---

## üèÅ 20. K·∫øt lu·∫≠n

H·ªá th·ªëng **LLM Provider Balancer** n√†y s·∫Ω l√† m·ªôt **l·ªõp trung gian th·ªëng nh·∫•t** gi√∫p:

* **Gom v√† t·ªëi ∆∞u h√≥a nhi·ªÅu provider LLM kh√°c nhau**,
* **C√¢n b·∫±ng th√¥ng minh** d·ª±a tr√™n usage, l·ªói, latency, chi ph√≠,
* **T∆∞∆°ng th√≠ch ho√†n to√†n OpenAI API** ƒë·ªÉ ng∆∞·ªùi d√πng **kh√¥ng c·∫ßn ƒë·ªïi SDK**,
* V√† ƒë∆∞·ª£c **vi·∫øt b·∫±ng Go** ‚Äî nh·∫π, nhanh, d·ªÖ deploy.
